# Data Cleaning Project

## 📌 Overview
This project demonstrates **data cleaning** techniques using Python.  
The goal is to handle messy data and transform it into a reliable dataset for further analysis.  
We used two datasets and applied cleaning operations to fix missing values, remove duplicates, standardize formats, and detect outliers.  

The project also generates a **data cleaning report** (`cleaned_data/data_cleaning_report.html`) that can be opened in a browser to view the cleaned dataset in a tabular format.

---

## 🗂️ Project Structure
Data_Cleaning_Project/
│── datasets/ # Raw input datasets (dataset1.csv, dataset2.csv)
│── cleaned_data/ # Stores cleaned datasets and report
│ └── data_cleaning_report.html
│── scripts/
│ └── data_cleaning.py # Main cleaning script
│── requirements.txt # Dependencies
│── README.md # Project documentation


---

## ⚡ Key Concepts and Challenges Addressed
1. **Data Integrity** – Ensured accuracy, consistency, and reliability throughout the process.  
2. **Missing Data Handling** – Filled or removed missing values as needed.  
3. **Duplicate Removal** – Identified and eliminated duplicate records.  
4. **Standardization** – Applied consistent formatting and units across datasets.  
5. **Outlier Detection** – Detected and handled outliers that could affect results.  

---

## 🚀 How to Run the Project
1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/Data_Cleaning_Project.git
   cd Data_Cleaning_Project

